{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"L4","mount_file_id":"1225qDLvr_SFUC4Oun57Wqm9Q86mNDY_X","authorship_tag":"ABX9TyOZAkc86uKq49a083oe/xZz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Notebook 5: Model Compression\n","## Introduction\n","# Loads models from Notebook 3, compresses for h=6 (chosen for balance), evaluates trade-offs.\n","# Justification: Dynamic/Float16/Int quantization for LSTM; param reduction/feature selection for RF. Ensures sustainability (lower energy) while maintaining ~95% accuracy.\n"],"metadata":{"id":"1zgSJMHgI98T"}},{"cell_type":"code","source":["import pandas as pd\n","import tensorflow as tf\n","import joblib\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.feature_selection import SelectFromModel\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","import os\n","import time\n","\n","chosen_h = 6\n","df = pd.read_csv('/content/drive/MyDrive/sus-lsa/featured_data.csv', index_col=0, parse_dates=True)\n","train_size = int(len(df) * 0.8)\n","train_df = df.iloc[:train_size]\n","test_df = df.iloc[train_size:]\n","features = [col for col in df.columns if col not in ['pm25_value', 'target']]\n","X_train = train_df[features]\n","y_train = train_df['target']\n","X_test = test_df[features]\n","y_test = test_df['target']\n","\n","# LSTM Compression\n","lstm = tf.keras.models.load_model(f'/content/drive/MyDrive/sus-lsa/lstm_model_h{chosen_h}.h5', custom_objects={'mse': tf.keras.metrics.MeanSquaredError()})\n","# Dynamic Quant\n","converter = tf.lite.TFLiteConverter.from_keras_model(lstm)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n","tflite_model = converter.convert()\n","with open(f'/content/drive/MyDrive/sus-lsa/lstm_dynamic_h{chosen_h}.tflite', 'wb') as f: f.write(tflite_model)\n","# Float16 Quant\n","converter = tf.lite.TFLiteConverter.from_keras_model(lstm)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","converter.target_spec.supported_types = [tf.float16]\n","converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n","tflite_float16 = converter.convert()\n","with open(f'/content/drive/MyDrive/sus-lsa/lstm_float16_h{chosen_h}.tflite', 'wb') as f: f.write(tflite_float16)\n","# Int Quant (third for robustness)\n","converter = tf.lite.TFLiteConverter.from_keras_model(lstm)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","def representative_dataset():\n","    for _ in range(100): yield [X_test.sample(1).values.astype(np.float32)]\n","converter.representative_dataset = representative_dataset\n","converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.SELECT_TF_OPS]\n","converter.inference_input_type = tf.int8\n","converter.inference_output_type = tf.int8\n","tflite_int = converter.convert()\n","with open(f'/content/drive/MyDrive/sus-lsa/lstm_int_h{chosen_h}.tflite', 'wb') as f: f.write(tflite_int)\n","\n","# Evaluate (example for dynamic; repeat for others)\n","interpreter = tf.lite.Interpreter(model_path=f'/content/drive/MyDrive/sus-lsa/lstm_dynamic_h{chosen_h}.tflite')\n","interpreter.allocate_tensors()\n","preds = []\n","start = time.time()\n","for x in X_test.values.reshape(-1, 1, len(features)):\n","    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], x.astype(np.float32))\n","    interpreter.invoke()\n","    preds.append(interpreter.get_tensor(interpreter.get_output_details()[0]['index']))\n","mae = mean_absolute_error(y_test, preds)\n","size = os.path.getsize(f'/content/drive/MyDrive/sus-lsa/lstm_dynamic_h{chosen_h}.tflite') / (1024*1024)\n","print(f'MAE: {mae}, Size: {size} MB, Time: {time.time() - start}s')\n","\n","# RF Compression\n","rf = joblib.load(f'/content/drive/MyDrive/sus-lsa/rf_model_h{chosen_h}.pkl')\n","# Feature Selection\n","selector = SelectFromModel(rf, prefit=True)\n","X_train_sel = selector.transform(X_train)\n","X_test_sel = selector.transform(X_test)\n","rf_sel = RandomForestRegressor(n_estimators=50)  # Reduced estimators\n","rf_sel.fit(X_train_sel, y_train)\n","joblib.dump(rf_sel, f'/content/drive/MyDrive/sus-lsa/rf_sel_h{chosen_h}.pkl')\n","# Param Reduction\n","rf_red = RandomForestRegressor(n_estimators=50, max_depth=10)\n","rf_red.fit(X_train, y_train)\n","joblib.dump(rf_red, f'/content/drive/MyDrive/sus-lsa/rf_red_h{chosen_h}.pkl')\n","# Evaluate similarly\n","\n","pd.DataFrame(compression_results).to_csv('/content/drive/MyDrive/sus-lsa/compression_results.csv')  # Justification: Compares size/accuracy trade-offs for sustainable AI.\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"FypvIpXoGbLc","executionInfo":{"status":"error","timestamp":1754018496656,"user_tz":-60,"elapsed":10348,"user":{"displayName":"SOM KAPOOR","userId":"07316503827781082392"}},"outputId":"036f56bf-1cdf-4b80-ed5b-0f22c8cb418c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved artifact at '/tmp/tmp0a972k12'. The following endpoints are available:\n","\n","* Endpoint 'serve'\n","  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 1, 18), dtype=tf.float32, name='input_layer_2')\n","Output Type:\n","  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n","Captures:\n","  137282919367888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  137282919370768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  137282919370960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  137284215124240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  137282919370384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"]},{"output_type":"error","ename":"ConverterError","evalue":"Could not translate MLIR to FlatBuffer.<unknown>:0: error: loc(callsite(callsite(fused[\"CudnnRNNV3:\", \"sequential_2_1/lstm_2_1/CudnnRNNV3@__inference_function_357\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_388\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.CudnnRNNV3' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: note: loc(callsite(callsite(fused[\"CudnnRNNV3:\", \"sequential_2_1/lstm_2_1/CudnnRNNV3@__inference_function_357\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_388\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): see current operation: %1:5 = \"tf.CudnnRNNV3\"(%arg0, %arg1, %arg2, %arg3, %arg4) {T = f32, device = \"\", direction = \"unidirectional\", dropout = 0.000000e+00 : f32, input_mode = \"linear_input\", is_training = true, num_proj = 0 : i64, rnn_mode = \"lstm\", seed = 0 : i64, seed2 = 0 : i64, time_major = false} : (tensor<?x1x18xf32>, tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<14000xf32>, tensor<?xi32>) -> (tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<*xf32>, tensor<*xi8>)\n<unknown>:0: note: loc(callsite(callsite(fused[\"CudnnRNNV3:\", \"sequential_2_1/lstm_2_1/CudnnRNNV3@__inference_function_357\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_388\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_CUSTOM_OPS\n<unknown>:0: error: failed while converting: 'main': \nSome ops in the model are custom ops, See instructions to implement custom ops: https://www.tensorflow.org/lite/guide/ops_custom \nCustom ops: CudnnRNNV3\nDetails:\n\ttf.CudnnRNNV3(tensor<?x1x18xf32>, tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<14000xf32>, tensor<?xi32>) -> (tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<*xf32>, tensor<*xi8>) : {T = f32, device = \"\", direction = \"unidirectional\", dropout = 0.000000e+00 : f32, input_mode = \"linear_input\", is_training = true, num_proj = 0 : i64, rnn_mode = \"lstm\", seed = 0 : i64, seed2 = 0 : i64, time_major = false}\n\n<unknown>:0: note: see current operation: \n\"func.func\"() <{arg_attrs = [{tf_saved_model.index_path = [\"input_layer_2\"]}], function_type = (tensor<?x1x18xf32>) -> tensor<?x1xf32>, res_attrs = [{tf_saved_model.index_path = [\"output_0\"]}], sym_name = \"main\"}> ({\n^bb0(%arg0: tensor<?x1x18xf32>):\n  %0 = \"arith.constant\"() <{value = dense<[-1, 50]> : tensor<2xi32>}> : () -> tensor<2xi32>\n  %1 = \"arith.constant\"() <{value = dense_resource<__elided__> : tensor<1x50xf32>}> : () -> tensor<1x50xf32>\n  %2 = \"arith.constant\"() <{value = dense_resource<__elided__> : tensor<14000xf32>}> : () -> tensor<14000xf32>\n  %3 = \"arith.constant\"() <{value = dense<0.0462510623> : tensor<1xf32>}> : () -> tensor<1xf32>\n  %4 = \"arith.constant\"() <{value = dense<1> : tensor<i32>}> : () -> tensor<i32>\n  %5 = \"arith.constant\"() <{value = dense<50> : tensor<i32>}> : () -> tensor<i32>\n  %6 = \"arith.constant\"() <{value = dense<0.000000e+00> : tensor<f32>}> : () -> tensor<f32>\n  %7 = \"arith.constant\"() <{value = dense<1> : tensor<1xi32>}> : () -> tensor<1xi32>\n  %8 = \"arith.constant\"() <{value = dense<0> : tensor<1xi32>}> : () -> tensor<1xi32>\n  %9 = \"tfl.shape\"(%arg0) : (tensor<?x1x18xf32>) -> tensor<3xi32>\n  %10 = \"tfl.strided_slice\"(%9, %8, %7, %7) <{begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, offset = false, shrink_axis_mask = 1 : i32}> : (tensor<3xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\n  %11 = \"tfl.reshape\"(%10, %7) : (tensor<i32>, tensor<1xi32>) -> tensor<1xi32>\n  %12 = \"tfl.fill\"(%11, %4) : (tensor<1xi32>, tensor<i32>) -> tensor<?xi32>\n  %13 = \"tfl.pack\"(%10, %5) <{axis = 0 : i32, values_count = 2 : i32}> : (tensor<i32>, tensor<i32>) -> tensor<2xi32>\n  %14 = \"tfl.fill\"(%13, %6) : (tensor<2xi32>, tensor<f32>) -> tensor<?x50xf32>\n  %15 = \"tfl.expand_dims\"(%14, %4) : (tensor<?x50xf32>, tensor<i32>) -> tensor<?x1x50xf32>\n  %16:5 = \"tfl.custom_tf\"(%arg0, %15, %15, %2, %12) ({\n  ^bb0(%arg1: tensor<?x1x18xf32>, %arg2: tensor<?x1x50xf32>, %arg3: tensor<?x1x50xf32>, %arg4: tensor<14000xf32>, %arg5: tensor<?xi32>):\n    %19:5 = \"tf.CudnnRNNV3\"(%arg1, %arg2, %arg3, %arg4, %arg5) {T = f32, device = \"\", direction = \"unidirectional\", dropout = 0.000000e+00 : f32, input_mode = \"linear_input\", is_training = true, num_proj = 0 : i64, rnn_mode = \"lstm\", seed = 0 : i64, seed2 = 0 : i64, time_major = false} : (tensor<?x1x18xf32>, tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<14000xf32>, tensor<?xi32>) -> (tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<*xf32>, tensor<*xi8>)\n    \"tfl.yield\"(%19#0, %19#1, %19#2, %19#3, %19#4) : (tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<*xf32>, tensor<*xi8>) -> ()\n  }) {T = f32, device = \"\", direction = \"unidirectional\", dropout = 0.000000e+00 : f32, input_mode = \"linear_input\", is_training = true, num_proj = 0 : i64, rnn_mode = \"lstm\", seed = 0 : i64, seed2 = 0 : i64, time_major = false} : (tensor<?x1x18xf32>, tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<14000xf32>, tensor<?xi32>) -> (tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<*xf32>, tensor<*xi8>)\n  %17 = \"tfl.reshape\"(%16#1, %0) : (tensor<?x1x50xf32>, tensor<2xi32>) -> tensor<?x50xf32>\n  %18 = \"tfl.fully_connected\"(%17, %1, %3) <{fused_activation_function = \"NONE\", keep_num_dims = false, weights_format = \"DEFAULT\"}> : (tensor<?x50xf32>, tensor<1x50xf32>, tensor<1xf32>) -> tensor<?x1xf32>\n  \"func.return\"(%18) : (tensor<?x1xf32>) -> ()\n}) {tf.entry_function = {control_outputs = \"\", inputs = \"serving_default_input_layer_2:0\", outputs = \"StatefulPartitionedCall_1:0\"}, tf_saved_model.exported_names = [\"serving_default\"]} : () -> ()\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1977789967.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupported_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpsSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLITE_BUILTINS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpsSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSELECT_TF_OPS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/content/drive/MyDrive/sus-lsa/lstm_dynamic_h{chosen_h}.tflite'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Float16 Quant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1236\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1238\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_and_export_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1239\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_convert_and_export_metrics\u001b[0;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_conversion_params_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m     \u001b[0melapsed_time_ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mInvalid\u001b[0m \u001b[0mquantization\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \"\"\"\n\u001b[0;32m-> 1754\u001b[0;31m     \u001b[0msaved_model_convert_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_as_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1755\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msaved_model_convert_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_convert_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_convert_as_saved_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1733\u001b[0m       )\n\u001b[1;32m   1734\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m         return super(TFLiteKerasModelConverterV2, self).convert(\n\u001b[0m\u001b[1;32m   1736\u001b[0m             \u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[1;32m   1471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m     \u001b[0;31m# Converts model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1473\u001b[0;31m     result = _convert_graphdef(\n\u001b[0m\u001b[1;32m   1474\u001b[0m         \u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m           \u001b[0mreport_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mconverter_error\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Re-throws the exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mreport_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mConverterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mconvert_graphdef\u001b[0;34m(input_data, input_tensors, output_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m       \u001b[0mmodel_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m   data = convert(\n\u001b[0m\u001b[1;32m   1029\u001b[0m       \u001b[0mmodel_flags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m       \u001b[0mconversion_flags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(model_flags, conversion_flags, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    374\u001b[0m               \u001b[0menable_mlir_converter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m           )\n\u001b[0;32m--> 376\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m   return _run_deprecated_conversion_binary(\n","\u001b[0;31mConverterError\u001b[0m: Could not translate MLIR to FlatBuffer.<unknown>:0: error: loc(callsite(callsite(fused[\"CudnnRNNV3:\", \"sequential_2_1/lstm_2_1/CudnnRNNV3@__inference_function_357\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_388\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.CudnnRNNV3' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: note: loc(callsite(callsite(fused[\"CudnnRNNV3:\", \"sequential_2_1/lstm_2_1/CudnnRNNV3@__inference_function_357\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_388\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): see current operation: %1:5 = \"tf.CudnnRNNV3\"(%arg0, %arg1, %arg2, %arg3, %arg4) {T = f32, device = \"\", direction = \"unidirectional\", dropout = 0.000000e+00 : f32, input_mode = \"linear_input\", is_training = true, num_proj = 0 : i64, rnn_mode = \"lstm\", seed = 0 : i64, seed2 = 0 : i64, time_major = false} : (tensor<?x1x18xf32>, tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<14000xf32>, tensor<?xi32>) -> (tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<*xf32>, tensor<*xi8>)\n<unknown>:0: note: loc(callsite(callsite(fused[\"CudnnRNNV3:\", \"sequential_2_1/lstm_2_1/CudnnRNNV3@__inference_function_357\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_388\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_CUSTOM_OPS\n<unknown>:0: error: failed while converting: 'main': \nSome ops in the model are custom ops, See instructions to implement custom ops: https://www.tensorflow.org/lite/guide/ops_custom \nCustom ops: CudnnRNNV3\nDetails:\n\ttf.CudnnRNNV3(tensor<?x1x18xf32>, tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<14000xf32>, tensor<?xi32>) -> (tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<*xf32>, tensor<*xi8>) : {T = f32, device = \"\", direction = \"unidirectional\", dropout = 0.000000e+00 : f32, input_mode = \"linear_input\", is_training = true, num_proj = 0 : i64, rnn_mode = \"lstm\", seed = 0 : i64, seed2 = 0 : i64, time_major = false}\n\n<unknown>:0: note: see current operation: \n\"func.func\"() <{arg_attrs = [{tf_saved_model.index_path = [\"input_layer_2\"]}], function_type = (tensor<?x1x18xf32>) -> tensor<?x1xf32>, res_attrs = [{tf_saved_model.index_path = [\"output_0\"]}], sym_name = \"main\"}> ({\n^bb0(%arg0: tensor<?x1x18xf32>):\n  %0 = \"arith.constant\"() <{value = dense<[-1, 50]> : tensor<2xi32>}> : () -> tensor<2xi32>\n  %1 = \"arith.constant\"() <{value = dense_resource<__elided__> : tensor<1x50xf32>}> : () -> tensor<1x50xf32>\n  %2 = \"arith.constant\"() <{value = dense_resource<__elided__> : tensor<14000xf32>}> : () -> tensor<14000xf32>\n  %3 = \"arith.constant\"() <{value = dense<0.0462510623> : tensor<1xf32>}> : () -> tensor<1xf32>\n  %4 = \"arith.constant\"() <{value = dense<1> : tensor<i32>}> : () -> tensor<i32>\n  %5 = \"arith.constant\"() <{value = dense<50> : tensor<i32>}> : () -> tensor<i32>\n  %6 = \"arith.constant\"() <{value = dense<0.000000e+00> : tensor<f32>}> : () -> tensor<f32>\n  %7 = \"arith.constant\"() <{value = dense<1> : tensor<1xi32>}> : () -> tensor<1xi32>\n  %8 = \"arith.constant\"() <{value = dense<0> : tensor<1xi32>}> : () -> tensor<1xi32>\n  %9 = \"tfl.shape\"(%arg0) : (tensor<?x1x18xf32>) -> tensor<3xi32>\n  %10 = \"tfl.strided_slice\"(%9, %8, %7, %7) <{begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, offset = false, shrink_axis_mask = 1 : i32}> : (tensor<3xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\n  %11 = \"tfl.reshape\"(%10, %7) : (tensor<i32>, tensor<1xi32>) -> tensor<1xi32>\n  %12 = \"tfl.fill\"(%11, %4) : (tensor<1xi32>, tensor<i32>) -> tensor<?xi32>\n  %13 = \"tfl.pack\"(%10, %5) <{axis = 0 : i32, values_count = 2 : i32}> : (tensor<i32>, tensor<i32>) -> tensor<2xi32>\n  %14 = \"tfl.fill\"(%13, %6) : (tensor<2xi32>, tensor<f32>) -> tensor<?x50xf32>\n  %15 = \"tfl.expand_dims\"(%14, %4) : (tensor<?x50xf32>, tensor<i32>) -> tensor<?x1x50xf32>\n  %16:5 = \"tfl.custom_tf\"(%arg0, %15, %15, %2, %12) ({\n  ^bb0(%arg1: tensor<?x1x18xf32>, %arg2: tensor<?x1x50xf32>, %arg3: tensor<?x1x50xf32>, %arg4: tensor<14000xf32>, %arg5: tensor<?xi32>):\n    %19:5 = \"tf.CudnnRNNV3\"(%arg1, %arg2, %arg3, %arg4, %arg5) {T = f32, device = \"\", direction = \"unidirectional\", dropout = 0.000000e+00 : f32, input_mode = \"linear_input\", is_training = true, num_proj = 0 : i64, rnn_mode = \"lstm\", seed = 0 : i64, seed2 = 0 : i64, time_major = false} : (tensor<?x1x18xf32>, tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<14000xf32>, tensor<?xi32>) -> (tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<*xf32>, tensor<*xi8>)\n    \"tfl.yield\"(%19#0, %19#1, %19#2, %19#3, %19#4) : (tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<*xf32>, tensor<*xi8>) -> ()\n  }) {T = f32, device = \"\", direction = \"unidirectional\", dropout = 0.000000e+00 : f32, input_mode = \"linear_input\", is_training = true, num_proj = 0 : i64, rnn_mode = \"lstm\", seed = 0 : i64, seed2 = 0 : i64, time_major = false} : (tensor<?x1x18xf32>, tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<14000xf32>, tensor<?xi32>) -> (tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<?x1x50xf32>, tensor<*xf32>, tensor<*xi8>)\n  %17 = \"tfl.reshape\"(%16#1, %0) : (tensor<?x1x50xf32>, tensor<2xi32>) -> tensor<?x50xf32>\n  %18 = \"tfl.fully_connected\"(%17, %1, %3) <{fused_activation_function = \"NONE\", keep_num_dims = false, weights_format = \"DEFAULT\"}> : (tensor<?x50xf32>, tensor<1x50xf32>, tensor<1xf32>) -> tensor<?x1xf32>\n  \"func.return\"(%18) : (tensor<?x1xf32>) -> ()\n}) {tf.entry_function = {control_outputs = \"\", inputs = \"serving_default_input_layer_2:0\", outputs = \"StatefulPartitionedCall_1:0\"}, tf_saved_model.exported_names = [\"serving_default\"]} : () -> ()\n"]}]}]}