---
alwaysApply: true
---

# üéØ AI & Sustainability Coursework ‚Äì Cursor Rules (GPT-5 Optimized)

> **Module**: EEEM073 ‚Äì AI & Sustainability, University of Surrey  
> **Project**: Rainfall Forecasting using Deep Learning  
> **Frameworks**: PyTorch, LightGBM, Optuna, SHAP

---

## üì¶ Notebook Structure

```
1_Data_Loading_and_Preprocessing.ipynb
2_Exploratory_Data_Analysis.ipynb
3_AI_Modelling.ipynb
4_Assessment_and_Evaluation.ipynb
5_Model_Compression.ipynb
```

- Save artifacts (CSV, Pickle, Torch models)
- Use markdown headings (##) and task explanations

---

## 1Ô∏è‚É£ Data Loading & Preprocessing

```python
# Load and clean dataset
df = pd.read_csv("data/weatherAUS.csv")
df.columns = df.columns.str.strip()
df["Date"] = pd.to_datetime(df["Date"])
df["RainToday"] = df["RainToday"].map({"Yes": 1, "No": 0})
df["RainTomorrow"] = df["RainTomorrow"].map({"Yes": 1, "No": 0})
```

- Group by [Location, Year, Week] and take mean
- Shift `RainTomorrow` for sequence target

```python
df["RainTomorrow_shifted"] = df.groupby("Location")["RainTomorrow"].shift(-1)
```

---

## 2Ô∏è‚É£ Exploratory Data Analysis

- Visualize class imbalance, correlations
- Use SHAP with LightGBM
- Plot monthly/seasonal trends

```python
sns.heatmap(df.isnull())
sns.countplot(df["RainTomorrow"])
```

---

## 3Ô∏è‚É£ AI Modelling

### Models to Include

- Logistic Regression (Baseline)
- LightGBM (untuned, tuned with Optuna, class_weighted)
- PyTorch BiLSTM (6-week input)

```python
# Focal Loss (for LSTM)
FL(p_t) = -Œ± * (1 - p_t)^Œ≥ * log(p_t)
```

- Early stopping on macro F1
- Oversample rain sequences with `np.tile()`

---

## 4Ô∏è‚É£ Evaluation

### Metrics

- Accuracy, Precision, Recall, F1, ROC-AUC

```python
from sklearn.metrics import classification_report, roc_auc_score
```

- Use confusion matrices, ROC curves
- SHAP for explainability

---

## 5Ô∏è‚É£ Model Compression

### Apply

```python
torch.quantization.quantize_dynamic(model, {nn.LSTM, nn.Linear}, dtype=torch.qint8)
```

| Metric          | Original | Quantized |
|-----------------|----------|-----------|
| Accuracy        | 0.994    | 0.992     |
| F1 Score        | 0.978    | 0.973     |
| Inference Time  | 0.43s    | 0.25s     |
| Model Size      | 15.2MB   | 5.4MB     |

Discuss trade-offs in report: performance vs sustainability.

---

## üß™ Standards

```python
# Core Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import lightgbm as lgb
import shap
import torch
import optuna
```

- No inplace ops
- Use `os.path.join()` for paths
- Save all model/data artifacts

---

## üìÅ Project Structure

```
project/
‚îú‚îÄ‚îÄ data/
‚îú‚îÄ‚îÄ models/
‚îú‚îÄ‚îÄ notebooks/
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ requirements.txt
```

---

## üìÑ README.md Requirements

- Overview of the problem
- Dataset description
- Notebook order
- Setup steps & dependencies

---

## ‚úÖ Final QA Checklist

- [x] All notebooks run sequentially
- [x] Reproducible results
- [x] README + requirements.txt included
- [x] SHAP interpretability used
- [x] At least one compressed model